{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f29dfed",
   "metadata": {},
   "source": [
    "## Importing Required Libraries\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9092132a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198f102e",
   "metadata": {},
   "source": [
    "## Data Gathering\n",
    "---\n",
    "Using `pd.read_csv`, load the data from  `Iris_Dataset.csv` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70c2027c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Data_Sets\\\\Iris_Dataset.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData_Sets\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mIris_Dataset.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data_Sets\\\\Iris_Dataset.csv'"
     ]
    }
   ],
   "source": [
    "file_path = r'Data_Sets\\Iris_Dataset.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7736e3e6",
   "metadata": {},
   "source": [
    "Reading top `5` rows from our `DataFrame` using `df.head()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbd9dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696a91c9",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "---\n",
    "Let's know the shape of our dataframe using `df.shape`. `df.shape[0]` will give us `number of rows` while `df.shape[1]` will give us `number of columns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e9ac87",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of Rows: ', df.shape[0])\n",
    "\n",
    "print('-' * 100)\n",
    "\n",
    "print('Number of Columns: ', df.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cf7049",
   "metadata": {},
   "source": [
    "Now let's check the data types of our features using `df.dtypes` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73087b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Data Types: \\n', df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c765b019",
   "metadata": {},
   "source": [
    "Here, All the `features/columns` are in numeric form i.e. either `int` or `float`, which is good. Only `Species` is in `Object` datatype. `Species` is our `Target` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe82f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Species.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca322959",
   "metadata": {},
   "source": [
    "Examine the species names and note that they all begin with `Iris-`. Remove this portion of the name so the species name is shorter. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a17ae47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Species'] = df.Species.apply(lambda r: r.replace('Iris-', ''))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b648161b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Species.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc93615b",
   "metadata": {},
   "source": [
    "Check contribution of each species using `pie-chart`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a520fce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "\n",
    "ax.axis('equal')\n",
    "\n",
    "data = df['Species'].value_counts()\n",
    "\n",
    "ax.pie(data, labels = data.keys(), autopct='%1.2f%%', colors='gry')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77771fc",
   "metadata": {},
   "source": [
    "Now, `Statistics` of dataframe can be checked using `df.describe`. This function give us `Mean`, `Median`, `Standard Deviation`,  etc.\n",
    "Here, `Median` Value is represented by `50 %`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec427623",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43c1628",
   "metadata": {},
   "source": [
    "Here, `Id` Column has unique continuous values which cannot contribute to predict Species type. Hence, we need to drop that column using `df.drop()` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a483ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = 'Id' , inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347c56c3",
   "metadata": {},
   "source": [
    "Check the information of Dataframe using `df.info()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bab85ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2011018",
   "metadata": {},
   "source": [
    "From the above results, we can conclude that there are `no null values` in our dataframe. we can verify this using `df.isna().sum()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb28532",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a639b2e4",
   "metadata": {},
   "source": [
    "#### Visualization\n",
    "---\n",
    "I will be using `Seaborn` and `Matplotlib` libraries for Data Visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b783cdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_continuous_distribution(data: pd.DataFrame = None, column: str = None, height: int = 5):\n",
    "    \n",
    "    _ = sns.displot(data, x=column, kde=True, height=height, aspect=height/5).set(title=f'Distribution of {column}')\n",
    "    plt.show() \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def correlation_plot(data: pd.DataFrame = None, numeric_only: bool = True, width: int = 10, height: int = 5):\n",
    "    \n",
    "    corr = data.corr(numeric_only = numeric_only)\n",
    "    \n",
    "    mask_ = np.array(corr)\n",
    "    mask_[np.tril_indices_from(mask_)] = False\n",
    "\n",
    "    fig , ax = plt.subplots()\n",
    "    fig.set_size_inches(width,height)\n",
    "    sns.heatmap(corr , mask = mask_ , vmax = 0.8 , square = True , annot = True , cmap = \"YlGnBu\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9191f04",
   "metadata": {},
   "source": [
    "##### 1. SepalLengthCm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8341bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_continuous_distribution(df, 'SepalLengthCm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a5985a",
   "metadata": {},
   "source": [
    "##### 2. SepalWidthCm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd15506",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_continuous_distribution(df, 'SepalWidthCm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0597164f",
   "metadata": {},
   "source": [
    "##### 3. PetalLengthCm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb61383",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_continuous_distribution(df, 'PetalLengthCm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d95f95f",
   "metadata": {},
   "source": [
    "##### 4. PetalWidthCm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b303301c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_continuous_distribution(df, 'PetalWidthCm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670fcc77",
   "metadata": {},
   "source": [
    "From the above plots we can conclude that:\n",
    "- Column `SepalWidthCm` is only `Distributed Normally`\n",
    "- Rest data is not `Normally Distributed` (Skewed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5e791d",
   "metadata": {},
   "source": [
    "We are creating a copy of Dataframe in order to check relation of `Species` with other features. For this, we will use `df.copy()` and `df['column_name'].replace({key : value})`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fcdb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.copy() \n",
    "data['Species'].replace({'setosa' : 0, 'versicolor' : 1, 'virginica' : 2} , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eceee98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_plot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e979f9f",
   "metadata": {},
   "source": [
    "###### Conclusion: \n",
    "\n",
    "- `SepalWidthCm` is fairly related with `Species` with a Correlation Coefficient of `-0.42`.\n",
    "- Correlation Coefficient shall be near to `1` or `-1` for `Best` correlation.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0508b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter_3d(df, x = 'SepalLengthCm', y = 'SepalWidthCm', z = 'PetalLengthCm', color = 'Species')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4577322e",
   "metadata": {},
   "source": [
    "From Scatter plot, we can say that the features are linearly separable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3117346c",
   "metadata": {},
   "source": [
    "###### Using `Pairplot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13beb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, hue='Species')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589b4359",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "---\n",
    "Check Skewness of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a95f0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_skewness(data: pd.DataFrame = None, target : str = None, limit : float = 0.75):\n",
    "    \n",
    "    skw = {}\n",
    "    \n",
    "    for column in data.columns:\n",
    "        \n",
    "        if column == target:\n",
    "            \n",
    "            continue\n",
    "        \n",
    "        sk_val = data[column].skew()\n",
    "        \n",
    "        if abs(sk_val) >= limit:            \n",
    "        \n",
    "            skw.update({column : sk_val})\n",
    "        \n",
    "    return skw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bab2879",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_skewness(df, 'Species')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e413db15",
   "metadata": {},
   "source": [
    "- Ideal skew value should be less than `0.75`.\n",
    "- No features are skewed from above result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5f12f1",
   "metadata": {},
   "source": [
    "#### Check for Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf4181b",
   "metadata": {},
   "source": [
    "- Using `sns.boxplot()`, we can check for outliers present in our data.\n",
    "- Outlier treatment method may differ based on feature importance or available data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3451f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df, x = 'SepalLengthCm', y = 'Species')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35827fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df, x = 'SepalWidthCm', y = 'Species')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c56901",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df, x = 'PetalLengthCm', y = 'Species')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fa6366",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df, x = 'PetalWidthCm', y = 'Species')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d994a00a",
   "metadata": {},
   "source": [
    "From results above, there are only few outliers present in individual `Species`. Hence, we can leave them as it is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da62a27",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92406087",
   "metadata": {},
   "source": [
    "It is not mandatory to perform feature scaling, but in this file we will be performing feature scaling. We will be `MinMax Scaler` which can be imported from `from sklearn.preprocessing import MinMaxScaler`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8861d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c362ff41",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb19c54",
   "metadata": {},
   "source": [
    "Before we fit data to our scaler, lets separate data from `target column`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4528a5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = 'Species') # alternatively we can use >> df.drop('Species' , axis = 1)\n",
    "Y = df['Species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5577384c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape , Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2abc8e0",
   "metadata": {},
   "source": [
    "Lets fit our data to the scaler object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb1a278",
   "metadata": {},
   "source": [
    "To fit data, we can use:\n",
    "- `fit()`  => We have to transform data in next step using `transform()` or\n",
    "- `fit_transform()` => No need to separatly transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d38b0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = scaler.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(arr, columns = X.columns)\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd18bc35",
   "metadata": {},
   "source": [
    "We need to save the scaling model for transforming data while testing. `Pickle` can be used to save model files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7216183b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963251d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'Task_1_Model_Files//Scaler.pkl'\n",
    "with open(path , 'wb') as f: # We can pass complete destination path where we want to save the file\n",
    "    \n",
    "    pickle.dump(scaler, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3cc8db",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "---\n",
    "- Using `from sklearn.model_selection import train_test_split` we can split data into training and testing.\n",
    "- Ideally `75 %` of data is used for `training` and rest for `testing`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8287f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2533fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fb2e31",
   "metadata": {},
   "source": [
    "`random_state` specifies that the dataset does not change everytime we execute cell. Thus ensuring the accuracy of model.\n",
    "Any `int` value can can assigned to `random_state`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36334c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X_scaled, Y, train_size = 0.75, random_state = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c7b1d3",
   "metadata": {},
   "source": [
    "###### Check the split data size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d2126f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape , x_test.shape , y_train.shape , y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42a5fe2",
   "metadata": {},
   "source": [
    "We are ready to train our model.\n",
    "We will train oour model on:\n",
    "\n",
    "- Logistic Regression\n",
    "- KNN Classifier\n",
    "- RandomForest Classifier\n",
    "- Adaboost Classifier\n",
    "\n",
    "Based on the accuracy, we would finalize the model from above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f366ec3",
   "metadata": {},
   "source": [
    "Let's import the models required.\n",
    "Also we will need to evaluate our model. Hence we will also import evaluation matrices like `confusion matrix`, `classification report`, `accuracy score`\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89b7f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing model libraries\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier , AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a815f20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing evaluation matrix libraries\n",
    "\n",
    "from sklearn.metrics import classification_report , accuracy_score\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1008fa19",
   "metadata": {},
   "source": [
    "#### 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5652bebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model = LogisticRegression(multi_class = 'ovr') # ovr > one verses rest\n",
    "log_model.fit(x_train , y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52677cd",
   "metadata": {},
   "source": [
    "##### Accuracy of `LogisticRegression` Model on Trainig Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90958560",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = log_model.predict(x_train)\n",
    "\n",
    "accuracy = round(accuracy_score(y_train , y_pred_train), 2)\n",
    "\n",
    "conf_mat = multilabel_confusion_matrix(y_train , y_pred_train)\n",
    "\n",
    "class_rep = classification_report(y_train , y_pred_train)\n",
    "\n",
    "print('-' * 100)\n",
    "\n",
    "print(f'Accuracy of model on training data is: {accuracy}')\n",
    "\n",
    "print('-' * 100)\n",
    "\n",
    "print(f'Classification Report of model on training data : \\n{class_rep}')\n",
    "\n",
    "print('-' * 100)\n",
    "\n",
    "print(f'Multilabel Confusion Matrix : \\n\\n {conf_mat}')\n",
    "\n",
    "print('-' * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4165938",
   "metadata": {},
   "source": [
    "##### Accuracy of `LogisticRegression` Model on Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc80ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = log_model.predict(x_test)\n",
    "\n",
    "accuracy = round(accuracy_score(y_test , y_pred), 2)\n",
    "\n",
    "conf_mat = multilabel_confusion_matrix(y_test , y_pred)\n",
    "\n",
    "class_rep = classification_report(y_test , y_pred)\n",
    "\n",
    "print('-' * 100)\n",
    "\n",
    "print(f'Accuracy of model on testing data is: {accuracy}')\n",
    "\n",
    "print('-' * 100)\n",
    "\n",
    "print(f'Classification Report of model on testing data : \\n{class_rep}')\n",
    "\n",
    "print('-' * 100)\n",
    "\n",
    "print(f'Multilabel Confusion Matrix : \\n\\n {conf_mat}')\n",
    "\n",
    "print('-' * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e55971",
   "metadata": {},
   "source": [
    "###### Conclusion : \n",
    "\n",
    "- Training Accuracy :  0.86\n",
    "- Testing Accuracy : 0.84\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e4c609",
   "metadata": {},
   "source": [
    "#### 2. KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34767f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNeighborsClassifier(n_neighbors = 5 , p = 2)\n",
    "knn_model.fit(x_train , y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de38833",
   "metadata": {},
   "source": [
    "##### Accuracy of `KNeighborsClassifier` Model on Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024280cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = knn_model.predict(x_train)\n",
    "\n",
    "accuracy = round(accuracy_score(y_train , y_pred_train), 2)\n",
    "\n",
    "conf_mat = multilabel_confusion_matrix(y_train , y_pred_train)\n",
    "\n",
    "class_rep = classification_report(y_train , y_pred_train)\n",
    "\n",
    "print('-' * 100)\n",
    "\n",
    "print(f'Accuracy of model on training data is: {accuracy}')\n",
    "\n",
    "print('-' * 100)\n",
    "\n",
    "print(f'Classification Report of model on training data : \\n{class_rep}')\n",
    "\n",
    "print('-' * 100)\n",
    "\n",
    "print(f'Multilabel Confusion Matrix : \\n\\n {conf_mat}')\n",
    "\n",
    "print('-' * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ec2e12",
   "metadata": {},
   "source": [
    "##### Accuracy of `KNeighborsClassifier` Model on Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bff86db",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn_model.predict(x_test)\n",
    "\n",
    "accuracy = round(accuracy_score(y_test , y_pred), 2)\n",
    "\n",
    "conf_mat = multilabel_confusion_matrix(y_test , y_pred)\n",
    "\n",
    "class_rep = classification_report(y_test , y_pred)\n",
    "\n",
    "print('-' * 100)\n",
    "\n",
    "print(f'Accuracy of model on testing data is: {accuracy}')\n",
    "\n",
    "print('-' * 100)\n",
    "\n",
    "print(f'Classification Report of model on testing data : \\n{class_rep}')\n",
    "\n",
    "print('-' * 100)\n",
    "\n",
    "print(f'Multilabel Confusion Matrix : \\n\\n {conf_mat}')\n",
    "\n",
    "print('-' * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e329f0",
   "metadata": {},
   "source": [
    "###### Conclusion : \n",
    "\n",
    "- Training Accuracy :  0.97\n",
    "- Testing Accuracy : 0.92\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bfc919",
   "metadata": {},
   "source": [
    "#### 3. RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89597174",
   "metadata": {},
   "outputs": [],
   "source": [
    "ran_model = RandomForestClassifier(n_jobs = -1 , random_state = 9)\n",
    "ran_model.fit(x_train , y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2dbff3",
   "metadata": {},
   "source": [
    "##### Accuracy of `RandomForestClassifier` Model on Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cce292",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = ran_model.predict(x_train)\n",
    "\n",
    "accuracy = round(accuracy_score(y_train , y_pred_train), 2)\n",
    "\n",
    "conf_mat = multilabel_confusion_matrix(y_train , y_pred_train)\n",
    "\n",
    "class_rep = classification_report(y_train , y_pred_train)\n",
    "\n",
    "print('-' * 100)\n",
    "\n",
    "print(f'Accuracy of model on training data is: {accuracy}')\n",
    "\n",
    "print('-' * 100)\n",
    "\n",
    "print(f'Classification Report of model on training data : \\n{class_rep}')\n",
    "\n",
    "print('-' * 100)\n",
    "\n",
    "print(f'Multilabel Confusion Matrix : \\n\\n {conf_mat}')\n",
    "\n",
    "print('-' * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669b78be",
   "metadata": {},
   "source": [
    "##### Accuracy of `RandomForestClassifier` Model on Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a2dd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ran_model.predict(x_test)\n",
    "\n",
    "accuracy = round(accuracy_score(y_test , y_pred), 2)\n",
    "\n",
    "conf_mat = multilabel_confusion_matrix(y_test , y_pred)\n",
    "\n",
    "class_rep = classification_report(y_test , y_pred)\n",
    "\n",
    "print('-' * 100)\n",
    "\n",
    "print(f'Accuracy of model on testing data is: {accuracy}')\n",
    "\n",
    "print('-' * 100)\n",
    "\n",
    "print(f'Classification Report of model on testing data : \\n{class_rep}')\n",
    "\n",
    "print('-' * 100)\n",
    "\n",
    "print(f'Multilabel Confusion Matrix : \\n\\n {conf_mat}')\n",
    "\n",
    "print('-' * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d54015",
   "metadata": {},
   "source": [
    "###### Conclusion : \n",
    "\n",
    "- Training Accuracy :  1.0\n",
    "- Testing Accuracy : 0.92\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febebbd7",
   "metadata": {},
   "source": [
    "#### 4. AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593684ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_model = AdaBoostClassifier(random_state = 6)\n",
    "ada_model.fit(x_train , y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203e14d9",
   "metadata": {},
   "source": [
    "##### Accuracy of `AdaBoostClassifier` Model on Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4782e270",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = ada_model.predict(x_train)\n",
    "\n",
    "accuracy = round(accuracy_score(y_train , y_pred_train), 2)\n",
    "\n",
    "conf_mat = multilabel_confusion_matrix(y_train , y_pred_train)\n",
    "\n",
    "class_rep = classification_report(y_train , y_pred_train)\n",
    "\n",
    "print('-' * 100)\n",
    "\n",
    "print(f'Accuracy of model on training data is: {accuracy}')\n",
    "\n",
    "print('-' * 100)\n",
    "\n",
    "print(f'Classification Report of model on training data : \\n{class_rep}')\n",
    "\n",
    "print('-' * 100)\n",
    "\n",
    "print(f'Multilabel Confusion Matrix : \\n\\n {conf_mat}')\n",
    "\n",
    "print('-' * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7b1806",
   "metadata": {},
   "source": [
    "##### Accuracy of `AdaBoostClassifier` Model on Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d48bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ada_model.predict(x_test)\n",
    "\n",
    "accuracy = round(accuracy_score(y_test , y_pred), 2)\n",
    "\n",
    "conf_mat = multilabel_confusion_matrix(y_test , y_pred)\n",
    "\n",
    "class_rep = classification_report(y_test , y_pred)\n",
    "\n",
    "print('-' * 100)\n",
    "\n",
    "print(f'Accuracy of model on testing data is: {accuracy}')\n",
    "\n",
    "print('-' * 100)\n",
    "\n",
    "print(f'Classification Report of model on testing data : \\n{class_rep}')\n",
    "\n",
    "print('-' * 100)\n",
    "\n",
    "print(f'Multilabel Confusion Matrix : \\n\\n {conf_mat}')\n",
    "\n",
    "print('-' * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f0551a",
   "metadata": {},
   "source": [
    "###### Conclusion : \n",
    "\n",
    "- Training Accuracy :  0.99\n",
    "- Testing Accuracy : 0.92\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5710e4a",
   "metadata": {},
   "source": [
    "After Hypertunning, we may bring good results to our model. We are selecting `AdaBoostClassifier` for hypertunning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74005f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_parameters = {'n_estimators' : np.arange(30 , 200), \n",
    "                    'learning_rate' : np.arange(0.1 , 1.0 , 0.1)\n",
    "                   }\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8f086c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_grcv = GridSearchCV(ada_model , hyper_parameters , cv = 5 , n_jobs = -1)\n",
    "ada_grcv.fit(x_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ddd38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "adagr_model = ada_grcv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98a8b6e",
   "metadata": {},
   "source": [
    "##### Accuracy of `Hypertuned AdaBoostClassifier` Model on Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15521bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = adagr_model.predict(x_train)\n",
    "\n",
    "accuracy = round(accuracy_score(y_train , y_pred_train), 2)\n",
    "\n",
    "conf_mat = multilabel_confusion_matrix(y_train , y_pred_train)\n",
    "\n",
    "class_rep = classification_report(y_train , y_pred_train)\n",
    "\n",
    "print('-' * 100)\n",
    "\n",
    "print(f'Accuracy of model on training data is: {accuracy}')\n",
    "\n",
    "print('-' * 100)\n",
    "\n",
    "print(f'Classification Report of model on training data : \\n{class_rep}')\n",
    "\n",
    "print('-' * 100)\n",
    "\n",
    "print(f'Multilabel Confusion Matrix : \\n\\n {conf_mat}')\n",
    "\n",
    "print('-' * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f632dea9",
   "metadata": {},
   "source": [
    "##### Accuracy of `Hypertuned AdaBoostClassifier` Model on Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1134f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = adagr_model.predict(x_test)\n",
    "\n",
    "accuracy = round(accuracy_score(y_test , y_pred), 2)\n",
    "\n",
    "conf_mat = multilabel_confusion_matrix(y_test , y_pred)\n",
    "\n",
    "class_rep = classification_report(y_test , y_pred)\n",
    "\n",
    "print('-' * 100)\n",
    "\n",
    "print(f'Accuracy of model on testing data is: {accuracy}')\n",
    "\n",
    "print('-' * 100)\n",
    "\n",
    "print(f'Classification Report of model on testing data : \\n{class_rep}')\n",
    "\n",
    "print('-' * 100)\n",
    "\n",
    "print(f'Multilabel Confusion Matrix : \\n\\n {conf_mat}')\n",
    "\n",
    "print('-' * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f50951",
   "metadata": {},
   "source": [
    "###### Conclusion : \n",
    "\n",
    "- Training Accuracy :  0.96\n",
    "- Testing Accuracy : 0.92\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ad7e15",
   "metadata": {},
   "source": [
    "###### Exporting Model File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f97c372",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Ada_model.pkl' , 'wb') as f:\n",
    "    \n",
    "    pickle.dump(adagr_model , f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c45e33",
   "metadata": {},
   "source": [
    "## Taking random samples for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60fc871",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = X_scaled[30 : 41]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d4ac06",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = adagr_model.predict(test)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3e1fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = Y[30 : 41]\n",
    "actual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d4d143",
   "metadata": {},
   "source": [
    "## Thank You\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
